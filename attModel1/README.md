# LSTM_Attention

GitHub 项目

[datalogue/keras-attention](https://github.com/datalogue/keras-attention/blob/master/models/custom_recurrents.py)

博客

[How to Develop an Encoder-Decoder Model with Attention for Sequence-to-Sequence Prediction in Keras](https://machinelearningmastery.com/encoder-decoder-attention-sequence-to-sequence-prediction-keras/)

### References

Bahdanau, Dzmitry, Kyunghyun Cho, and Yoshua Bengio. ["Neural machine translation by jointly learning to align and translate." arXiv preprint arXiv:1409.0473 (2014).](https://arxiv.org/abs/1409.0473)

